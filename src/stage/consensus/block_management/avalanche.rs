use super::BlockManagement;
use crate::config::AvalancheConfig;

use crate::context::{BlkCtx, TxnCtx};
use crate::protocol::block::{Block, BlockHeader};
use crate::protocol::crypto::{sha256, Hash};
use crate::protocol::transaction::{AvalancheTxn, Txn};
use crate::protocol::CryptoScheme;
use crate::utils::{CopycatError, NodeId};

use async_trait::async_trait;

use primitive_types::U256;
use tokio::sync::Notify;
use tokio::time::{Duration, Instant};

use std::collections::{HashMap, HashSet, VecDeque};
use std::sync::Arc;

struct DagNode {
    pub num_parents: usize,
    pub children: HashSet<Hash>,
}

pub struct AvalancheBlockManagement {
    id: NodeId,
    crypto_scheme: CryptoScheme,
    blk_len: usize,
    txn_pool: HashMap<Hash, (Arc<Txn>, Arc<TxnCtx>)>,
    txn_dag: HashMap<Hash, DagNode>,
    dag_frontier: VecDeque<Hash>,
    // fields for constructing new block
    blk_counter: u64,
    curr_batch: Vec<Hash>,
    next_propose_time: Instant,
    proposal_timeout: Duration,
    _notify: Notify,
}

impl AvalancheBlockManagement {
    pub fn new(id: NodeId, crypto_scheme: CryptoScheme, config: AvalancheConfig) -> Self {
        let proposal_timeout = Duration::from_secs_f64(config.proposal_timeout_secs);
        Self {
            id,
            crypto_scheme,
            blk_len: config.blk_len,
            txn_pool: HashMap::new(),
            txn_dag: HashMap::new(),
            dag_frontier: VecDeque::new(),
            // for batching txns into blocks
            blk_counter: 0,
            curr_batch: vec![],
            next_propose_time: Instant::now() + proposal_timeout,
            proposal_timeout,
            _notify: Notify::new(),
        }
    }
}

impl AvalancheBlockManagement {
    fn validate_txn(&self, txn: &AvalancheTxn) -> Result<bool, CopycatError> {
        match txn {
            AvalancheTxn::Send {
                sender: txn_sender,
                in_utxo: txn_in_utxo,
                out_utxo: txn_out_utxo,
                remainder: txn_remainder,
                ..
            } => {
                let mut input_value = 0;
                for in_utxo_hash in txn_in_utxo.iter() {
                    // first check that input transactions exists, we can check for double spend later as a block
                    // add values together to find total input value
                    let utxo = match self.txn_pool.get(in_utxo_hash) {
                        Some((txn, _)) => match txn.as_ref() {
                            Txn::Avalanche { txn } => txn,
                            _ => unreachable!(),
                        },
                        None => return Ok(false), // invalid utxo
                    };

                    let value = match utxo {
                        AvalancheTxn::Grant { out_utxo, receiver } => {
                            if receiver == txn_sender {
                                out_utxo
                            } else {
                                return Ok(false); // utxo does not belong to sender
                            }
                        }
                        AvalancheTxn::Send {
                            sender,
                            receiver,
                            out_utxo,
                            remainder,
                            ..
                        } => {
                            if receiver == txn_sender {
                                out_utxo
                            } else if sender == txn_sender {
                                remainder
                            } else {
                                return Ok(false); // utxo does not belong to sender
                            }
                        }
                        AvalancheTxn::Noop { .. } | AvalancheTxn::PlaceHolder => {
                            unreachable!();
                        }
                    };
                    input_value += value;
                }

                // check if the input values match output values
                if input_value != txn_out_utxo + txn_remainder {
                    return Ok(false); // input and output utxo values do not match
                }
            }
            AvalancheTxn::Grant { .. } | AvalancheTxn::Noop { .. } => {
                // grant txns are always correct
                // noops are generated by other nodes to drive consensus and does nothing
            }
            AvalancheTxn::PlaceHolder => {
                unreachable!();
            }
        }

        Ok(true)
    }
}

#[async_trait]
impl BlockManagement for AvalancheBlockManagement {
    async fn record_new_txn(
        &mut self,
        txn: Arc<Txn>,
        ctx: Arc<TxnCtx>,
    ) -> Result<bool, CopycatError> {
        let txn_hash = ctx.id;
        // ignore duplicates
        if self.txn_pool.contains_key(&txn_hash) {
            return Ok(false);
        }

        let avax_txn = match txn.as_ref() {
            Txn::Avalanche { txn } => txn,
            _ => unreachable!(),
        };

        if !self.validate_txn(avax_txn)? {
            return Ok(false);
        }

        self.txn_pool
            .insert(txn_hash.clone(), (txn.clone(), ctx.clone()));

        let parents = match avax_txn {
            AvalancheTxn::Grant { .. } => vec![],
            AvalancheTxn::Send { in_utxo, .. } => in_utxo.clone(),
            AvalancheTxn::Noop { .. } | AvalancheTxn::PlaceHolder => unreachable!(), // since Noops are generated by nodes only
        };

        let mut in_frontier = true;
        for parent in parents.iter() {
            if let Some(siblings) = self.txn_dag.get_mut(parent) {
                siblings.children.insert(txn_hash);
                in_frontier = false;
            }
        }

        self.txn_dag.insert(
            txn_hash,
            DagNode {
                num_parents: parents.len(),
                children: HashSet::new(),
            },
        );

        if in_frontier {
            self.dag_frontier.push_back(txn_hash);
        }

        Ok(true)
    }

    async fn prepare_new_block(&mut self) -> Result<(), CopycatError> {
        loop {
            if self.curr_batch.len() > self.blk_len {
                break;
            }

            let next_txn = match self.dag_frontier.pop_front() {
                Some(txn) => txn,
                None => break,
            };

            let node = self.txn_dag.remove(&next_txn).unwrap();
            for child in node.children {
                let child_node = match self.txn_dag.get_mut(&child) {
                    Some(node) => node,
                    None => continue,
                };

                // remove node from its parents
                child_node.num_parents -= 1;
                // if all parents removed, add it to frontier
                if child_node.num_parents == 0 {
                    self.dag_frontier.push_back(child);
                }
            }

            self.curr_batch.push(next_txn);
        }

        Ok(())
    }

    async fn wait_to_propose(&self) -> Result<(), CopycatError> {
        if self.curr_batch.len() == 0 {
            // TODO: add noop txns so that parent txns can get voted on
            // sleep forever
            loop {
                self._notify.notified().await;
            }
        } else if self.curr_batch.len() >= self.blk_len {
            return Ok(());
        } else {
            tokio::time::sleep_until(self.next_propose_time).await;
            return Ok(());
        }
    }

    async fn get_new_block(&mut self) -> Result<(Arc<Block>, Arc<BlkCtx>), CopycatError> {
        //TODO: add noop txns to drive consensus as needed
        let txn_hashs: Vec<Hash> = self.curr_batch.drain(0..).collect();
        let txns_with_ctx: Vec<(Arc<Txn>, Arc<TxnCtx>)> = txn_hashs
            .iter()
            .map(|txn_hash| self.txn_pool.get(&txn_hash).unwrap().clone())
            .collect();
        let txns = txns_with_ctx.iter().map(|(txn, _)| txn.clone()).collect();
        let txn_ctx: Vec<Arc<TxnCtx>> = txns_with_ctx.iter().map(|(_, ctx)| ctx.clone()).collect();

        let header = BlockHeader::Avalanche {
            proposer: self.id,
            id: self.blk_counter,
        };
        pf_debug!(self.id; "sending block query {:?} ({} txns)", header, txn_hashs.len());
        let blk = Arc::new(Block { header, txns });
        self.blk_counter += 1;
        self.next_propose_time = Instant::now() + self.proposal_timeout;
        assert!(blk.txns.len() == txn_ctx.len());
        Ok((
            blk,
            Arc::new(BlkCtx {
                id: U256::zero(), // since we do not use hash to identify txn batches
                txn_ctx,
            }),
        ))
    }

    async fn validate_block(
        &mut self,
        block: Arc<Block>,
    ) -> Result<Vec<(Arc<Block>, Arc<BlkCtx>)>, CopycatError> {
        let mut filtered_txns = vec![];
        let mut blk_txn_ctx = vec![];
        for txn in block.txns.iter() {
            let txn_hash = sha256(&bincode::serialize(txn.as_ref())?)?;

            if let Some((_, txn_ctx)) = self.txn_pool.get(&txn_hash) {
                // txn has been validated before
                filtered_txns.push(txn.clone());
                blk_txn_ctx.push(txn_ctx.clone());
                continue;
            }

            // I have not seen this txn before, adding to txn_pool and txn_dag so that it will get proposed later
            let avax_txn = match txn.as_ref() {
                Txn::Avalanche { txn } => txn,
                _ => unreachable!(),
            };

            let (txn, txn_ctx) = match avax_txn {
                AvalancheTxn::Noop { .. } | AvalancheTxn::PlaceHolder => {
                    // if noop txn, bypass all tests since it is just used to drive consensus
                    // placeholder txns should not be sent across nodes but if this is the case, keep as is
                    // they do not need to be add to txn pool
                    (txn.clone(), Arc::new(TxnCtx { id: U256::zero() }))
                }
                AvalancheTxn::Grant { .. } => {
                    let ctx = Arc::new(TxnCtx { id: txn_hash });
                    self.txn_pool
                        .insert(txn_hash.clone(), (txn.clone(), ctx.clone()));
                    self.txn_dag.insert(
                        txn_hash,
                        DagNode {
                            num_parents: 0,
                            children: HashSet::new(),
                        },
                    );
                    (txn.clone(), ctx)
                }
                AvalancheTxn::Send {
                    sender,
                    in_utxo,
                    sender_signature,
                    ..
                } => {
                    // verify signature
                    let serialized_in_txo = bincode::serialize(in_utxo)?;
                    let mut valid = !self
                        .crypto_scheme
                        .verify(sender, &serialized_in_txo, sender_signature)
                        .await?;

                    // verify validity
                    if valid {
                        valid = self.validate_txn(avax_txn)?;
                    }

                    if valid {
                        // add to txn pool if valid
                        let ctx = Arc::new(TxnCtx { id: txn_hash });
                        self.txn_pool
                            .insert(txn_hash.clone(), (txn.clone(), ctx.clone()));
                        let mut in_frontier = true;
                        for parent in in_utxo.iter() {
                            if let Some(siblings) = self.txn_dag.get_mut(parent) {
                                siblings.children.insert(txn_hash);
                                in_frontier = false;
                            }
                        }
                        if in_frontier {
                            self.dag_frontier.push_back(txn_hash);
                        } else {
                            self.txn_dag.insert(
                                txn_hash,
                                DagNode {
                                    num_parents: in_utxo.len(),
                                    children: HashSet::new(),
                                },
                            );
                        }
                        (txn.clone(), ctx)
                    } else {
                        // otherwise put a place holder
                        (
                            Arc::new(Txn::Avalanche {
                                txn: AvalancheTxn::PlaceHolder,
                            }),
                            Arc::new(TxnCtx { id: U256::zero() }),
                        )
                    }
                }
            };
            filtered_txns.push(txn);
            blk_txn_ctx.push(txn_ctx);
        }

        assert!(filtered_txns.len() == block.txns.len());

        let blk = Arc::new(Block {
            header: block.header.clone(),
            txns: filtered_txns,
        });
        assert!(blk.txns.len() == blk_txn_ctx.len());
        Ok(vec![(
            blk,
            Arc::new(BlkCtx {
                id: U256::zero(),
                txn_ctx: blk_txn_ctx,
            }),
        )])
    }

    async fn handle_pmaker_msg(&mut self, _msg: Arc<Vec<u8>>) -> Result<(), CopycatError> {
        todo!();
    }

    async fn handle_peer_blk_req(
        &mut self,
        _peer: NodeId,
        _blk_id: Hash,
    ) -> Result<(), CopycatError> {
        unreachable!();
    }
}
